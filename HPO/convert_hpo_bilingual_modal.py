#!/usr/bin/env python3
"""
HPO to Bilingual Vietnamese/English Symptom Dataset Converter

Uses Modal for GPU-accelerated translation with NLLB-200.
Generates yes/no questions with bilingual terms: Vietnamese (English)

Target: 20,000 samples (10,000 True + 10,000 False pairs)
"""

import modal
import json
import random
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass

# ================= CONFIGURATION =================
SEED = 42
TARGET_PAIRS = 10000  # Will generate 20,000 total (10k True + 10k False)
BATCH_SIZE = 128  # Translation batch size (optimized for A10G)
TEST_MODE = False  # Set True to test with 1 batch only
TEST_BATCH_SIZE = 50  # Number of relationships for test mode
OUTPUT_TRAIN = "hpo_vietnamese_bilingual_train.jsonl"
OUTPUT_TEST = "hpo_vietnamese_bilingual_test.jsonl"
OUTPUT_STATS = "hpo_vietnamese_bilingual_stats.json"

# Modal configuration
app = modal.App("hpo-bilingual-translation")
volume = modal.Volume.from_name("medical-data", create_if_missing=True)

# GPU image with translation model
translation_image = (
    modal.Image.debian_slim(python_version="3.11")
    .pip_install(
        "torch>=2.0.0",
        "transformers>=4.35.0",
        "sentencepiece",
        "accelerate",
        "tqdm"
    )
)

# Bilingual templates - Vietnamese question with English in parentheses
TEMPLATES_TRUE = [
    "{child_vi} ({child_en}) cÃ³ pháº£i lÃ  má»™t dáº¡ng cá»§a {parent_vi} ({parent_en}) khÃ´ng?",
    "Trong y há»c, {child_vi} ({child_en}) thuá»™c nhÃ³m {parent_vi} ({parent_en}) Ä‘Ãºng khÃ´ng?",
    "XÃ¡c nháº­n: {child_vi} (hay {child_en}) lÃ  biá»ƒu hiá»‡n liÃªn quan Ä‘áº¿n {parent_vi} ({parent_en})?",
    "{child_vi} ({child_en}) cÃ³ thuá»™c loáº¡i {parent_vi} ({parent_en}) khÃ´ng?",
    "Triá»‡u chá»©ng {child_vi} ({child_en}) cÃ³ náº±m trong nhÃ³m {parent_vi} ({parent_en}) khÃ´ng?",
    "{child_vi} ({child_en}) cÃ³ liÃªn quan Ä‘áº¿n {parent_vi} ({parent_en}) khÃ´ng?",
    "Biá»ƒu hiá»‡n {child_vi} ({child_en}) cÃ³ pháº£i lÃ  má»™t pháº§n cá»§a {parent_vi} ({parent_en}) khÃ´ng?",
    "{child_vi} ({child_en}) Ä‘Æ°á»£c xáº¿p vÃ o loáº¡i {parent_vi} ({parent_en}) pháº£i khÃ´ng?",
]

TEMPLATES_FALSE = [
    "{child_vi} ({child_en}) cÃ³ pháº£i lÃ  má»™t dáº¡ng cá»§a {fake_parent_vi} ({fake_parent_en}) khÃ´ng?",
    "CÃ³ pháº£i {child_vi} ({child_en}) thuá»™c nhÃ³m triá»‡u chá»©ng {fake_parent_vi} ({fake_parent_en})?",
    "XÃ¡c nháº­n: {child_vi} (hay {child_en}) lÃ  biá»ƒu hiá»‡n cá»§a {fake_parent_vi} ({fake_parent_en})?",
    "{child_vi} ({child_en}) cÃ³ thuá»™c loáº¡i {fake_parent_vi} ({fake_parent_en}) khÃ´ng?",
    "Triá»‡u chá»©ng {child_vi} ({child_en}) cÃ³ náº±m trong nhÃ³m {fake_parent_vi} ({fake_parent_en}) khÃ´ng?",
    "{child_vi} ({child_en}) cÃ³ liÃªn quan Ä‘áº¿n {fake_parent_vi} ({fake_parent_en}) khÃ´ng?",
    "Biá»ƒu hiá»‡n {child_vi} ({child_en}) cÃ³ pháº£i lÃ  má»™t pháº§n cá»§a {fake_parent_vi} ({fake_parent_en}) khÃ´ng?",
    "{child_vi} ({child_en}) Ä‘Æ°á»£c xáº¿p vÃ o loáº¡i {fake_parent_vi} ({fake_parent_en}) pháº£i khÃ´ng?",
]

# Multiple instruction templates for variety
INSTRUCTIONS = [
    "Dá»±a trÃªn kiáº¿n thá»©c triá»‡u chá»©ng y há»c, tráº£ lá»i ÄÃºng hoáº·c Sai.",
    "HÃ£y cho biáº¿t cÃ¢u sau Ä‘Ãºng hay sai dá»±a vÃ o kiáº¿n thá»©c y khoa.",
    "XÃ¡c Ä‘á»‹nh tÃ­nh Ä‘Ãºng sai cá»§a nháº­n Ä‘á»‹nh sau vá» triá»‡u chá»©ng y há»c.",
    "Tráº£ lá»i ÄÃºng hoáº·c Sai cho cÃ¢u há»i y khoa sau.",
    "Dá»±a vÃ o phÃ¢n loáº¡i triá»‡u chá»©ng y há»c, hÃ£y tráº£ lá»i ÄÃºng hoáº·c Sai.",
    "Vá»›i kiáº¿n thá»©c vá» bá»‡nh há»c, hÃ£y xÃ¡c nháº­n cÃ¢u sau ÄÃºng hay Sai.",
    "CÃ¢u há»i vá» má»‘i quan há»‡ triá»‡u chá»©ng - Tráº£ lá»i ÄÃºng hoáº·c Sai.",
    "Theo há»‡ thá»‘ng phÃ¢n loáº¡i y khoa, cÃ¢u sau ÄÃºng hay Sai?",
]


@dataclass
class HPORelationship:
    """Represents an HPO is_a relationship"""
    child_id: str
    child_en: str
    parent_id: str
    parent_en: str


@app.cls(
    image=translation_image,
    gpu="A10G",
    timeout=7200,
    volumes={"/data": volume},
    retries=3
)
class BilingualTranslator:
    """GPU-accelerated translator using NLLB-200"""
    
    @modal.enter()
    def setup(self):
        """Load model on container start"""
        import torch
        from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
        
        print("ğŸ”„ Loading NLLB-200 translation model...")
        model_name = "facebook/nllb-200-distilled-600M"
        
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        self.model = AutoModelForSeq2SeqLM.from_pretrained(
            model_name,
            torch_dtype=torch.float16
        ).cuda()
        self.model.eval()
        
        # Source and target language codes for NLLB
        self.src_lang = "eng_Latn"
        self.tgt_lang = "vie_Latn"
        
        print("âœ… Model loaded successfully!")
    
    def _translate_batch_internal(self, texts: List[str]) -> List[str]:
        """Internal method to translate a batch of English texts to Vietnamese"""
        import torch
        
        if not texts:
            return []
        
        # Clean texts (remove "obsolete" prefix common in HPO)
        cleaned_texts = [t.replace("obsolete ", "").strip() for t in texts]
        
        # Set source language
        self.tokenizer.src_lang = self.src_lang
        
        # Tokenize batch
        inputs = self.tokenizer(
            cleaned_texts,
            return_tensors="pt",
            padding=True,
            truncation=True,
            max_length=128
        ).to("cuda")
        
        # Generate translations
        with torch.no_grad():
            generated_tokens = self.model.generate(
                **inputs,
                forced_bos_token_id=self.tokenizer.convert_tokens_to_ids(self.tgt_lang),
                max_length=128,
                num_beams=5,
                early_stopping=True
            )
        
        # Decode translations
        translations = self.tokenizer.batch_decode(
            generated_tokens, 
            skip_special_tokens=True
        )
        
        # Fallback: if translation is same as input, keep English
        results = []
        for orig, trans in zip(cleaned_texts, translations):
            if trans.lower() == orig.lower() or not trans.strip():
                results.append(orig)
            else:
                results.append(trans)
        
        return results
    
    @modal.method()
    def translate_relationships(
        self, 
        relationships: List[Dict],
        all_node_labels: List[str]
    ) -> Tuple[List[Dict], List[Dict]]:
        """
        Translate HPO relationships and generate bilingual QA pairs.
        
        Args:
            relationships: List of dicts with child_id, child_en, parent_id, parent_en
            all_node_labels: List of all HPO term labels for fake parent selection
            
        Returns:
            Tuple of (true_samples, false_samples)
        """
        import random
        from tqdm import tqdm
        
        random.seed(SEED)
        
        # Collect unique terms to translate
        terms_to_translate = set()
        for rel in relationships:
            terms_to_translate.add(rel['child_en'])
            terms_to_translate.add(rel['parent_en'])
        
        # Add some random terms for fake parents
        fake_parent_pool = random.sample(all_node_labels, min(len(all_node_labels), 5000))
        terms_to_translate.update(fake_parent_pool)
        
        terms_list = list(terms_to_translate)
        print(f"ğŸ“ Translating {len(terms_list)} unique terms...")
        
        # Translate in batches using internal method
        translation_map = {}
        for i in tqdm(range(0, len(terms_list), BATCH_SIZE), desc="Translating"):
            batch = terms_list[i:i + BATCH_SIZE]
            translations = self._translate_batch_internal(batch)
            for term, trans in zip(batch, translations):
                translation_map[term] = trans
        
        print(f"âœ… Translated {len(translation_map)} terms")
        
        # Generate QA pairs
        true_samples = []
        false_samples = []
        
        for rel in tqdm(relationships, desc="Generating QA pairs"):
            child_en = rel['child_en']
            parent_en = rel['parent_en']
            child_vi = translation_map.get(child_en, child_en)
            parent_vi = translation_map.get(parent_en, parent_en)
            
            # 1. Generate TRUE sample with random instruction
            template = random.choice(TEMPLATES_TRUE)
            instruction = random.choice(INSTRUCTIONS)
            question = template.format(
                child_vi=child_vi, child_en=child_en,
                parent_vi=parent_vi, parent_en=parent_en
            )
            
            true_samples.append({
                "instruction": instruction,
                "input": question,
                "output": "ÄÃºng",
                "question_type": "true_relationship",
                "child_en": child_en,
                "child_vi": child_vi,
                "parent_en": parent_en,
                "parent_vi": parent_vi
            })
            
            # 2. Generate FALSE sample with random fake parent and instruction
            fake_parent_en = random.choice(fake_parent_pool)
            while fake_parent_en == parent_en or fake_parent_en == child_en:
                fake_parent_en = random.choice(fake_parent_pool)
            
            fake_parent_vi = translation_map.get(fake_parent_en, fake_parent_en)
            
            template_false = random.choice(TEMPLATES_FALSE)
            instruction_false = random.choice(INSTRUCTIONS)
            question_false = template_false.format(
                child_vi=child_vi, child_en=child_en,
                fake_parent_vi=fake_parent_vi, fake_parent_en=fake_parent_en
            )
            
            false_samples.append({
                "instruction": instruction_false,
                "input": question_false,
                "output": "Sai",
                "question_type": "false_relationship",
                "child_en": child_en,
                "child_vi": child_vi,
                "fake_parent_en": fake_parent_en,
                "fake_parent_vi": fake_parent_vi
            })
        
        return true_samples, false_samples


@app.function(
    image=modal.Image.debian_slim().pip_install("tqdm"),
    volumes={"/data": volume},
    timeout=600
)
def load_hpo_data() -> Tuple[List[Dict], List[str]]:
    """Load HPO data and extract relationships"""
    import json
    import random
    
    random.seed(SEED)
    
    print("ğŸ“‚ Loading HPO data from volume...")
    
    # Try to load from volume first, then from local
    hpo_path = "/data/hp.json"
    
    with open(hpo_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    graphs = data['graphs'][0]
    nodes = {n['id']: n for n in graphs['nodes']}
    edges = graphs['edges']
    
    # Get all node labels for fake parent selection
    all_labels = [n.get('lbl', '') for n in graphs['nodes'] if n.get('lbl')]
    
    # Filter valid is_a relationships
    relationships = []
    for edge in edges:
        if edge.get('pred') != 'is_a':
            continue
            
        child_id = edge['sub']
        parent_id = edge['obj']
        
        if child_id not in nodes or parent_id not in nodes:
            continue
            
        child_en = nodes[child_id].get('lbl', '')
        parent_en = nodes[parent_id].get('lbl', '')
        
        if not child_en or not parent_en:
            continue
        
        # Skip root term
        if "All" in parent_en or parent_id.endswith("HP_0000001"):
            continue
            
        relationships.append({
            'child_id': child_id,
            'child_en': child_en,
            'parent_id': parent_id,
            'parent_en': parent_en
        })
    
    print(f"ğŸ“Š Found {len(relationships)} valid relationships")
    
    # Sample relationships based on mode
    random.shuffle(relationships)
    
    if TEST_MODE:
        sampled = relationships[:TEST_BATCH_SIZE]
        print(f"ğŸ§ª TEST MODE: Using only {len(sampled)} relationships")
    else:
        sampled = relationships[:TARGET_PAIRS]
        print(f"ğŸ“‹ Sampled {len(sampled)} relationships for translation")
    
    return sampled, all_labels


@app.function(
    image=modal.Image.debian_slim().pip_install("tqdm"),
    volumes={"/data": volume},
    timeout=300
)
def save_results(true_samples: List[Dict], false_samples: List[Dict]):
    """Save translated samples to volume"""
    import json
    import random
    
    random.seed(SEED)
    
    # Combine and shuffle
    all_samples = true_samples + false_samples
    random.shuffle(all_samples)
    
    # Split train/test (90/10)
    split_idx = int(len(all_samples) * 0.9)
    train_samples = all_samples[:split_idx]
    test_samples = all_samples[split_idx:]
    
    # Save to volume
    train_path = f"/data/{OUTPUT_TRAIN}"
    test_path = f"/data/{OUTPUT_TEST}"
    stats_path = f"/data/{OUTPUT_STATS}"
    
    with open(train_path, 'w', encoding='utf-8') as f:
        for sample in train_samples:
            json.dump(sample, f, ensure_ascii=False)
            f.write('\n')
    
    with open(test_path, 'w', encoding='utf-8') as f:
        for sample in test_samples:
            json.dump(sample, f, ensure_ascii=False)
            f.write('\n')
    
    # Statistics
    stats = {
        "total_samples": len(all_samples),
        "train_samples": len(train_samples),
        "test_samples": len(test_samples),
        "true_samples": len(true_samples),
        "false_samples": len(false_samples),
        "balance_ratio": f"{len(true_samples)}:{len(false_samples)}",
        "templates_used": {
            "true": len(TEMPLATES_TRUE),
            "false": len(TEMPLATES_FALSE)
        },
        "translation_model": "facebook/nllb-200-distilled-600M",
        "bilingual_format": "Vietnamese (English)"
    }
    
    with open(stats_path, 'w', encoding='utf-8') as f:
        json.dump(stats, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… Saved {len(train_samples)} train samples to {train_path}")
    print(f"âœ… Saved {len(test_samples)} test samples to {test_path}")
    print(f"âœ… Saved statistics to {stats_path}")
    
    # Commit volume
    volume.commit()
    
    return stats


@app.local_entrypoint()
def main():
    """Main entry point for Modal execution"""
    mode_str = "ğŸ§ª TEST MODE" if TEST_MODE else "ğŸš€ PRODUCTION MODE"
    target = TEST_BATCH_SIZE if TEST_MODE else TARGET_PAIRS
    
    print(f"{mode_str} - HPO Bilingual Translation Pipeline")
    print(f"ğŸ“Š Target: {target} pairs = {target * 2} total samples")
    print(f"ğŸ“¦ Batch size: {BATCH_SIZE}")
    
    # Step 1: Load HPO data
    print("\nğŸ“‚ Step 1: Loading HPO data...")
    relationships, all_labels = load_hpo_data.remote()
    print(f"   Loaded {len(relationships)} relationships")
    
    # Step 2: Translate and generate QA pairs
    print("\nğŸ”„ Step 2: Translating and generating QA pairs...")
    translator = BilingualTranslator()
    true_samples, false_samples = translator.translate_relationships.remote(
        relationships, 
        all_labels
    )
    print(f"   Generated {len(true_samples)} true + {len(false_samples)} false samples")
    
    # Step 3: Save results
    print("\nğŸ’¾ Step 3: Saving results...")
    stats = save_results.remote(true_samples, false_samples)
    
    print("\n" + "="*50)
    print("ğŸ‰ HPO Bilingual Translation Complete!")
    print("="*50)
    print(f"Mode: {mode_str}")
    print(f"Total samples: {stats['total_samples']}")
    print(f"Train: {stats['train_samples']}, Test: {stats['test_samples']}")
    print(f"Balance: {stats['balance_ratio']}")
    print("\nğŸ“¥ Download with:")
    print(f"   modal volume get medical-data {OUTPUT_TRAIN} ./")
    print(f"   modal volume get medical-data {OUTPUT_TEST} ./")
    print(f"   modal volume get medical-data {OUTPUT_STATS} ./")


# For testing locally without Modal
def test_templates():
    """Test template formatting"""
    sample_data = {
        "child_vi": "Chá»©ng ráº­m lÃ´ng",
        "child_en": "Hirsutism",
        "parent_vi": "Ráº­m lÃ´ng toÃ n thÃ¢n",
        "parent_en": "Generalized hirsutism",
        "fake_parent_vi": "Äau Ä‘áº§u",
        "fake_parent_en": "Headache"
    }
    
    print("=== TRUE Templates ===")
    for tmpl in TEMPLATES_TRUE:
        print(tmpl.format(**sample_data))
    
    print("\n=== FALSE Templates ===")
    for tmpl in TEMPLATES_FALSE:
        print(tmpl.format(**sample_data))


if __name__ == "__main__":
    # Local test
    test_templates()
