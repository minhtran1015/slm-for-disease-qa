#!/usr/bin/env python3
"""
PhÃ¢n tÃ­ch Dataset DrugBank Viá»‡t Nam Má»Ÿ Rá»™ng
Hiá»ƒn thá»‹ thá»‘ng kÃª vÃ  vÃ­ dá»¥ vá» dataset Ä‘Ã£ bá»• sung thuá»‘c Viá»‡t Nam
"""

import json
from collections import Counter

def analyze_extended_dataset():
    print("ğŸ‡»ğŸ‡³ PHÃ‚N TÃCH DATASET DRUGBANK VIá»†T NAM Má» Rá»˜NG")
    print("=" * 70)
    
    # Äá»c dataset má»Ÿ rá»™ng
    train_file = "drugbank_qa_vietnamese_extended_train.jsonl"
    test_file = "drugbank_qa_vietnamese_extended_test.jsonl" 
    analysis_file = "drugbank_qa_vietnamese_extended_analysis.json"
    
    train_data = []
    with open(train_file, 'r', encoding='utf-8') as f:
        for line in f:
            train_data.append(json.loads(line))
    
    test_data = []
    with open(test_file, 'r', encoding='utf-8') as f:
        for line in f:
            test_data.append(json.loads(line))
    
    with open(analysis_file, 'r', encoding='utf-8') as f:
        analysis = json.load(f)
    
    # Thá»‘ng kÃª tá»•ng quan
    print(f"ğŸ“Š THá»NG KÃŠ Tá»”NG QUAN:")
    print(f"   â€¢ Dataset gá»‘c (DrugBank): {analysis['original_dataset']['total_samples']:,} máº«u")
    print(f"   â€¢ Thuá»‘c Viá»‡t Nam bá»• sung: {analysis['vietnamese_addition']['total_samples']:,} máº«u")  
    print(f"   â€¢ Dataset má»Ÿ rá»™ng: {analysis['extended_dataset']['total_samples']:,} máº«u")
    print(f"   â€¢ TÄƒng thÃªm: {analysis['vietnamese_addition']['total_samples']}/{analysis['original_dataset']['total_samples']*100:.1f}%")
    
    # PhÃ¢n tÃ­ch cÃ¢n báº±ng
    train_answers = Counter(item['output'] for item in train_data)
    test_answers = Counter(item['output'] for item in test_data)
    
    print(f"\nğŸ¯ CÃ‚N Báº°NG Dá»® LIá»†U:")
    print(f"   Training Set:")
    for answer, count in train_answers.items():
        pct = count/len(train_data)*100
        print(f"      â€¢ {answer}: {count:,} máº«u ({pct:.1f}%)")
    
    print(f"   Test Set:")
    for answer, count in test_answers.items():
        pct = count/len(test_data)*100  
        print(f"      â€¢ {answer}: {count:,} máº«u ({pct:.1f}%)")
    
    # PhÃ¢n loáº¡i cÃ¡c loáº¡i thuá»‘c
    print(f"\nğŸ’Š PHÃ‚N LOáº I THUá»C ÄÃƒ Bá»” SUNG:")
    
    # Thuá»‘c thÃ´ng dá»¥ng tiáº¿ng Anh
    print("   Thuá»‘c thÃ´ng dá»¥ng (tÃªn quá»‘c táº¿):")
    for drug in analysis['vietnamese_drug_examples']:
        print(f"      â€¢ {drug}")
    
    # Thuá»‘c Viá»‡t hÃ³a  
    print("   Thuá»‘c Viá»‡t hÃ³a (tÃªn dÃ¢n gian):")
    for name in analysis['vietnamese_name_examples']:
        print(f"      â€¢ {name}")
    
    # TÃ¬m vÃ­ dá»¥ cá»¥ thá»ƒ trong dataset
    print(f"\nğŸŒŸ VÃ Dá»¤ Cá»¤ THá»‚ TRONG DATASET:")
    
    # VÃ­ dá»¥ thuá»‘c thÃ´ng dá»¥ng
    common_drugs = ['Paracetamol', 'Aspirin', 'Vitamin C', 'Amoxicillin']
    for drug in common_drugs[:3]:
        examples = [item for item in train_data if drug in item['input']]
        if examples:
            ex = examples[0]
            print(f"   ğŸ“ {drug}:")
            print(f"      Q: {ex['input']}")
            print(f"      A: {ex['output']}")
            print()
    
    # VÃ­ dá»¥ thuá»‘c Viá»‡t hÃ³a
    vietnamese_phrases = ['Thuá»‘c giáº£m Ä‘au', 'Thuá»‘c dáº¡ dÃ y', 'KhÃ¡ng sinh']
    for phrase in vietnamese_phrases[:2]:
        examples = [item for item in train_data if phrase in item['input']]
        if examples:
            ex = examples[0]
            print(f"   ğŸ“ {phrase}:")
            print(f"      Q: {ex['input']}")
            print(f"      A: {ex['output']}")
            print()
    
    # ÄÃ¡nh giÃ¡ Ä‘á»™ phá»§
    print(f"ğŸ“ˆ Äá»˜ PHá»¦ THUá»C VIá»†T NAM:")
    
    # Äáº¿m cÃ¢u há»i cÃ³ chá»©a thuá»‘c phá»• biáº¿n
    common_drug_count = 0
    vietnamese_phrase_count = 0
    
    all_data = train_data + test_data
    
    for item in all_data:
        text = item['input'].lower()
        
        # Thuá»‘c phá»• biáº¿n
        common_drugs_lower = [d.lower() for d in ['paracetamol', 'aspirin', 'vitamin', 'amoxicillin', 'ibuprofen']]
        if any(drug in text for drug in common_drugs_lower):
            common_drug_count += 1
        
        # Cá»¥m tá»« Viá»‡t hÃ³a
        vietnamese_phrases_lower = ['thuá»‘c giáº£m Ä‘au', 'thuá»‘c dáº¡ dÃ y', 'khÃ¡ng sinh', 'vitamin']
        if any(phrase in text for phrase in vietnamese_phrases_lower):
            vietnamese_phrase_count += 1
    
    total_samples = len(all_data)
    print(f"   â€¢ CÃ¢u há»i chá»©a thuá»‘c phá»• biáº¿n: {common_drug_count:,}/{total_samples:,} ({common_drug_count/total_samples*100:.1f}%)")
    print(f"   â€¢ CÃ¢u há»i chá»©a thuáº­t ngá»¯ Viá»‡t: {vietnamese_phrase_count:,}/{total_samples:,} ({vietnamese_phrase_count/total_samples*100:.1f}%)")
    
    # Gá»£i Ã½ sá»­ dá»¥ng
    print(f"\nğŸš€ KHUYáº¾N NGHá»Š Sá»¬ Dá»¤NG:")
    print(f"   â€¢ Dataset nÃ y phÃ¹ há»£p Ä‘á»ƒ test vá»›i tÃªn thuá»‘c Viá»‡t Nam phá»• biáº¿n")
    print(f"   â€¢ Bao gá»“m cáº£ tÃªn khoa há»c vÃ  tÃªn thÃ´ng dá»¥ng")
    print(f"   â€¢ CÃ³ thá»ƒ xá»­ lÃ½ cÃ¢u há»i vá» thuá»‘c báº±ng tiáº¿ng Viá»‡t tá»± nhiÃªn")
    print(f"   â€¢ Sáºµn sÃ ng cho training vá»›i Gemma/Qwen trÃªn dá»¯ liá»‡u Viá»‡t Nam")
    
    print(f"\nğŸ“ FILES ÄÆ¯á»¢C Táº O:")
    print(f"   â€¢ {train_file} ({len(train_data):,} máº«u training)")
    print(f"   â€¢ {test_file} ({len(test_data):,} máº«u test)")
    print(f"   â€¢ {analysis_file} (thá»‘ng kÃª chi tiáº¿t)")

if __name__ == "__main__":
    analyze_extended_dataset()